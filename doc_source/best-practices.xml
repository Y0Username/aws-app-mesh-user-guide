<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE chapter PUBLIC "-//OASIS//DTD DocBook XML V4.5//EN" "file://zonbook/docbookx.dtd"
 [
  <!ENTITY % xinclude SYSTEM "file://AWSShared/common/xinclude.mod">
    %xinclude;
    <!ENTITY % phrases-shared SYSTEM "file://AWSShared/common/phrases-shared.ent">
    %phrases-shared;
    <!ENTITY % phrases-appmesh SYSTEM "../shared/phrases-app-mesh.ent"> 
    %phrases-appmesh;
 ]>
<chapter id="best-practices">
    <info>
        <title id="best-practices.title">&MESH; best practices</title>
        <titleabbrev>Best practices</titleabbrev>
        <abstract>
            <para>Learn about best practices for using &MESH;.</para>
        </abstract>
    </info>
    <!-- <para>This chapter discusses best practices for using &MESH;. Select one of the following areas
        to review best practices for that area.</para>
    <para role="topiclist"/> -->
    <para>To achieve the goal of zero failed requests during planned deployments and during the
            unplanned loss of some hosts, the best practices in this topic implement the following
            strategy:</para>
            <itemizedlist>
                <listitem>
                    <para>Increase the likelihood that a request will succeed from the perspective
                        of the application by using a safe default retry strategy. For more
                        information, see <xref linkend="route-retries" endterm="route-retries.title"/>.</para>
                </listitem>
                <listitem>
                    <para>Increase the likelihood that a retried request succeeds by maximizing the
                        likelihood that the retried request is sent to an actual destination. For
                        more information, see <xref linkend="reduce-deployment-velocity" endterm="reduce-deployment-velocity.title"/>, <xref
                            linkend="scale-out" endterm="scale-out.title"/>, and <xref linkend="health-checks" endterm="health-checks.title"/>.</para>
                </listitem>
            </itemizedlist>
            <para>To significantly reduce or eliminate failures, we recommend that you implement the
                recommendations in all of the following practices.</para>
    <!-- <section id="bp-minimizing-downtime" role="topic">
        <info>
            <title id="bp-minimizing-downtime.title">Minimizing downtime during planned and
                unplanned events</title>
            <titleabbrev>Minimizing downtime</titleabbrev>
        </info>    
        <para>To achieve the goal of zero failed requests during planned deployments and during the
            unplanned loss of some hosts, the best practices in this topic implement the following
            strategy:</para>
            <itemizedlist>
                <listitem>
                    <para>Increase the likelihood that a request will succeed from the perspective
                        of the application by using a safe default retry strategy. For more
                        information, see <xref linkend="route-retries"/>.</para>
                </listitem>
                <listitem>
                    <para>Increase the likelihood that a retried request succeeds by maximizing the
                        likelihood that the retried request is sent to an actual destination. For
                        more information, see <xref linkend="reduce-deployment-velocity"/>, <xref
                            linkend="scale-out"/>, and <xref linkend="health-checks"/>.</para>
                </listitem>
            </itemizedlist>
            <para>To significantly reduce or eliminate failures, we recommend that you implement the
                recommendations in all of the following practices.</para> -->
            <section id="route-retries">
                <info>
                    <title id="route-retries.title">Instrument all routes with retries</title>
                </info>
                <para>Configure all virtual services to use a virtual router and set a default retry
                    policy for all routes. This will mitigate failed requests by reselecting a host
                    and sending a new request.
                    <!--In the near-term, we are deploying a change to our configuration which will force Envoy to avoid selecting hosts that were used on previous attempts, and in the mid-to-long-term we are investigating adding default retry policies to virtual nodes without a virtual router and on routes without a retry policy defined.-->
                    For retry policies, we recommend a value of at least two for
                        <code>maxRetries</code>, and specifying the following options for each type
                    of retry event in each route type that supports the retry event type:</para>
                <itemizedlist>
                    <listitem>
                        <para><emphasis role="bold">TCP</emphasis> &endash;
                                <code>connection-error</code></para>
                    </listitem>
                    <listitem>
                        <para><emphasis role="bold">HTTP and HTTP/2</emphasis> &endash;
                                <code>stream-error</code> and <code>gateway-error</code></para>
                    </listitem>
                    <listitem>
                        <para><emphasis role="bold">gRPC</emphasis> &endash; <code>cancelled</code>
                            and <code>unavailable</code></para>
                    </listitem>
                </itemizedlist>
                <para>Other retry events need to be considered on a case-by-case basis as they may
                    not be safe, such as if the request isn’t idempotent. You will need to consider
                    and test values for <code>maxRetries</code> and <code>perRetryTimeout</code>
                    that make the appropriate trade off between the maximum latency of a request
                        (<code>maxRetries</code> * <code>perRetryTimeout</code>) versus the
                    increased success rate of more retries. Additionally, when Envoy attempts to
                    connect to an endpoint that is no longer present, you should expect that request
                    to consume the full <code>perRetryTimeout</code>. To configure a retry policy,
                    see <link linkend="create-route" endterm="create-route.title"/> and then select the protocol that you want to
                    route.</para>
                <note><para>If you implemented a route on or after &default-route-retry-policy-date; and didn't specify a
                retry policy, then &MESH; may have automatically created a default retry policy
                similar to the previous policy for each route you created on or after
                &default-route-retry-policy-date;. For more information, see <xref
                    linkend="default-retry-policy" endterm="default-retry-policy.title"/>.</para></note>
            </section>
            <section id="reduce-deployment-velocity">
                <info>
                    <title id="reduce-deployment-velocity.title">Adjust deployment velocity</title>
                </info>
                <para>When using rolling deployments, reduce the overall deployment velocity. By
                    default, &ECS; configures a deployment strategy of a minimum of 100 percent
                    healthy tasks and 200 percent total tasks. On deployment, this results in two
                    points of high drift:</para>
                <itemizedlist>
                    <listitem>
                        <para>The 100 percent fleet size of new tasks may be visible to Envoys prior
                            to being ready to complete requests (see <xref linkend="health-checks" endterm="health-checks.title"/>
                            for mitigations).</para>
                    </listitem>
                    <listitem>
                        <para>The 100 percent fleet size of old tasks may be visible to Envoys while
                            the tasks are being terminated.</para>
                    </listitem>
                </itemizedlist>
                <para>When configured with these deployment constraints, container orchestrators may
                    enter a state where they are simultaneously hiding all old destinations and
                    making all new destinations visible. Because your Envoy dataplane is eventually
                    consistent, this can result in periods where the set of destinations visible in
                    your dataplane have diverged from the orchestrator’s point of view. To mitigate
                    this, we recommend maintaining a minimum of 100 percent healthy tasks, but
                    lowering total tasks to 125 percent. This will reduce divergence and improve the
                    reliability of retries. We recommend the following settings for different
                    container runtimes:</para>
                <para><!--Worst case, in either of the two states listed previously, there is a 50 percent chance that a retry will select yet another failing destination. To mitigate this, we recommend maintaining a minimum of 100 percent healthy tasks, but lowering total tasks to 125 percent. This reduces the drift to between approximately 25 percent to 20 percent of tasks, improving the reliability of retries. We recommend the following settings for different container runtimes: --></para>
                <formalpara>
                    <title>&ECS;</title>
                    <para>If your service has a desired count of two or three, set
                            <code>maximumPercent</code> to 150 percent. Otherwise, set
                            <code>maximumPercent</code> to 125 percent.</para>
                </formalpara>
                <formalpara>
                    <title>Kubernetes</title>
                    <para>Configure your deployment's <ulink
                            url="https://v1-16.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.16/#deploymentstrategy-v1beta2-apps"
                            >update strategy</ulink>, setting <code>maxUnavailable</code> to 0
                        percent and <code>maxSurge</code> to 25 percent. </para>
                </formalpara>
            </section>
            <section id="scale-out">
                <info>
                    <title id="scale-out.title">Scale out before scale in</title>
                </info>
                <para>Scale out and scale in can both result in some probability of failed requests
                    in retries. While there are task recommendations that mitigate scale out, the
                    only recommendation for scale in is to minimize the percentage of scaled in
                    tasks at any one time. We recommend that you use a deployment strategy that
                    scales out new &ECS; tasks or Kubernetes deployments prior to scaling in old
                    tasks or deployments. This scaling strategy keeps your percentage of scaled in
                    tasks or deployments lower, while maintaining the same velocity. This practice
                    applies to both &ECS; tasks and Kubernetes deployments.</para>
            </section>
            <section id="health-checks">
                <info>
                    <title id="health-checks.title">Implement container health checks</title>
                </info>
                <para>In the scale up scenario, containers in an &ECS; task may come up out of order
                    and may not be initially responsive. We recommend the following suggestions for
                    different container runtimes:</para>
                <formalpara>
                    <title>&ECS;</title>
                    <para>To mitigate this, we recommend using container health checks and container
                        dependency ordering to ensure that Envoy is running and healthy prior to any
                        containers requiring outbound network connectivity starting. To correctly
                        configure an application container and Envoy container in a task definition,
                        see <ulink type="documentation"
                            url="AmazonECS/latest/developerguide/example_task_definitions.html#example_task_definition-containerdependency"
                            >Container dependency</ulink>.</para>
                </formalpara>
                <formalpara>
                    <title>Kubernetes</title>
                    <para>None, because Kubernetes <ulink
                            url="https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/"
                            >liveness and readiness</ulink> probes are not being considered in
                        registration and de-registration of &CMAP; instances in the <ulink
                            url="https://github.com/aws/aws-app-mesh-controller-for-k8s">&MESH;
                            controller for Kubernetes</ulink>. For more information, see GitHub
                        issue <ulink
                            url="https://github.com/aws/aws-app-mesh-controller-for-k8s/issues/132"
                            >#132</ulink>.</para>
                </formalpara>
            </section>
    <!-- </section>
    <section id="bp-monitoring" role="topic">
        <info>
            <title id="bp-monitoring.title">Monitoring and failure resolution</title>
            <titleabbrev>Monitoring</titleabbrev>
        </info>
        <para>We recommend that you monitor the metrics discussed in this topic when using
            &MESH;.</para>
        <formalpara>
            <title>Application metrics</title>
            <para>While the observability metrics Envoy provides you will help you better diagnose
                issues between services, it’s also important to remember that failures in your
                service mesh may not be translating into issues for your services and customers.
                Similarly, seeing no issues in your Envoy metrics doesn’t mean that your
                applications are healthy.</para>
        </formalpara>

        <formalpara>
            <title>Envoy metrics</title>
            <para>Envoy can be configured to emit metrics to a variety of sinks such as <link
                    linkend="ts-bp-enable-envoy-statsd-integration"><code>DogStatsD</code></link>
                which can be published to &CWlong;. These metrics can also be queried for from the
                Envoy admin interface, which is typically <ulink url="http://address:9901/"
                    >http://address:9901</ulink>. For more information, see <link
                    linkend="ts-bp-enable-proxy-admin-interface"/>. For simplicity, output from the
                admin interface is shown in the examples that follow.</para>
        </formalpara>

        <para>Within Envoy, metrics are categorized as either applying to the <code>egress</code>
            traffic leaving your application or <code>ingress</code> traffic coming to your
            application. Envoy further categories traffic based on which side of the connection the
            metric refers to, where <code>downstream</code> is the original sender of traffic and
                <code>upstream</code> is the next receiver of traffic.</para>

        <para>You can start understanding what Envoy is doing by viewing the classes of HTTP
            responses that Envoy has returned to your application <code>downstream</code> for
            outbound requests (<code>egress</code>).</para>
        <programlisting role="nocopy">http.egress.downstream_rq_1xx: <replaceable>0</replaceable>
http.egress.downstream_rq_2xx: <replaceable>29953240</replaceable>
http.egress.downstream_rq_3xx: <replaceable>0</replaceable>
http.egress.downstream_rq_4xx: <replaceable>189</replaceable>
http.egress.downstream_rq_5xx:<replaceable> 1852</replaceable>
http.egress.downstream_rq_active: <replaceable>0</replaceable>
http.egress.downstream_rq_completed: <replaceable>29955281</replaceable></programlisting>
        <para>You can also view example metrics for responses returned to applications that are
            calling your service (<code>ingress</code>).</para>
        <programlisting role="nocopy">http.ingress.downstream_rq_1xx: <replaceable>0</replaceable>
http.ingress.downstream_rq_2xx: <replaceable>12598783</replaceable>
http.ingress.downstream_rq_3xx: <replaceable>0</replaceable>
http.ingress.downstream_rq_4xx: <replaceable>16</replaceable>
http.ingress.downstream_rq_5xx: <replaceable>2042</replaceable>
http.ingress.downstream_rq_active: <replaceable>0</replaceable>
http.ingress.downstream_rq_completed: <replaceable>126</replaceable></programlisting>
        <para>These previous metrics are a view of what your application is seeing, and what other
            applications in your service mesh should be seeing. To understand more about the
                <code>upstream</code> traffic, you need to look at what Envoy sees from its
            connection pools. Metrics for these pools have the following format:</para>
        <programlisting>cluster.cds_${ingress|egress}_${<replaceable>mesh</replaceable>}_${<replaceable>destination_virtual_node</replaceable>}_${<replaceable>protocol</replaceable>}_${<replaceable>port</replaceable>}.${<replaceable>metric</replaceable>}</programlisting>
        <para>For ingress traffic, the <replaceable>destination_virtual_node</replaceable> is always
            your application's virtual node.</para>
            
            <para>The following example metrics are for a virtual node named
                <replaceable>virtual-node-a</replaceable> that's in a mesh named
                <replaceable>prod</replaceable>. </para>
        <programlisting role="nocopy">cluster.cds_egress_<replaceable>prod</replaceable>_<replaceable>virtual-node-a</replaceable>_http_3000.upstream_rq_200: <replaceable>8974819</replaceable>
cluster.cds_egress_<replaceable>prod</replaceable>_<replaceable>virtual-node-a</replaceable>_http_3000.upstream_rq_2xx: <replaceable>8974819</replaceable>
cluster.cds_egress_<replaceable>prod</replaceable>_<replaceable>virtual-node-a</replaceable>_http_3000.upstream_rq_409: <replaceable>189</replaceable>
cluster.cds_egress_<replaceable>prod</replaceable>_<replaceable>virtual-node-a</replaceable>_http_3000.upstream_rq_4xx: <replaceable>189</replaceable>
cluster.cds_egress_<replaceable>prod</replaceable>_<replaceable>virtual-node-a</replaceable>_http_3000.upstream_rq_500: <replaceable>5</replaceable>
cluster.cds_egress_<replaceable>prod</replaceable>_<replaceable>virtual-node-a</replaceable>_http_3000.upstream_rq_504: <replaceable>2</replaceable>
cluster.cds_egress_<replaceable>prod</replaceable>_<replaceable>virtual-node-a</replaceable>_http_3000.upstream_rq_5xx: <replaceable>7</replaceable>
cluster.cds_egress_<replaceable>prod</replaceable>_<replaceable>virtual-node-a</replaceable>_http_3000.upstream_rq_per_try_timeout: <replaceable>3</replaceable>
cluster.cds_egress_<replaceable>prod</replaceable>_<replaceable>virtual-node-a</replaceable>_http_3000.upstream_rq_retry: <replaceable>1</replaceable>
cluster.cds_egress_<replaceable>prod</replaceable>_<replaceable>virtual-node-a</replaceable>_http_3000.upstream_rq_retry_overflow: <replaceable>0</replaceable>
cluster.cds_egress_<replaceable>prod</replaceable>_<replaceable>virtual-node-a</replaceable>_http_3000.upstream_rq_retry_success: <replaceable>1</replaceable></programlisting>
        <para>The previous example metrics show nearly 9 million <code>200</code> requests, with a
            small number of conflict and server exceptions.</para>
        <para>You can also see metrics on request timeouts, as well as when retries have occurred,
            and whether they succeeded.</para>
    <programlisting role="nocopy">cluster.cds_egress_<replaceable>prod</replaceable>_<replaceable>virtual-node-a</replaceable>_http_3000.health_check.attempt: <replaceable>94540</replaceable>
cluster.cds_egress_<replaceable>prod</replaceable>_<replaceable>virtual-node-a</replaceable>_http_3000.health_check.degraded: <replaceable>0</replaceable>
cluster.cds_egress_<replaceable>prod</replaceable>_<replaceable>virtual-node-a</replaceable>_http_3000.health_check.failure: <replaceable>0</replaceable>
cluster.cds_egress_<replaceable>prod</replaceable>_<replaceable>virtual-node-a</replaceable>_http_3000.health_check.healthy: <replaceable>3</replaceable>
cluster.cds_egress_<replaceable>prod</replaceable>_<replaceable>virtual-node-a</replaceable>_http_3000.health_check.network_failure: <replaceable>0</replaceable>
cluster.cds_egress_<replaceable>prod</replaceable>_<replaceable>virtual-node-a</replaceable>_http_3000.health_check.passive_failure: <replaceable>0</replaceable>
cluster.cds_egress_<replaceable>prod</replaceable>_<replaceable>virtual-node-a</replaceable>_http_3000.health_check.success: <replaceable>94540</replaceable>
cluster.cds_egress_<replaceable>prod</replaceable>_<replaceable>virtual-node-a</replaceable>_http_3000.health_check.verify_cluster: <replaceable>0</replaceable>
cluster.cds_egress_<replaceable>prod</replaceable>_<replaceable>virtual-node-a</replaceable>_http_3000.membership_change: <replaceable>1</replaceable>
cluster.cds_egress_<replaceable>prod</replaceable>_<replaceable>virtual-node-a</replaceable>_http_3000.membership_degraded: <replaceable>0</replaceable>
cluster.cds_egress_<replaceable>prod</replaceable>_<replaceable>virtual-node-a</replaceable>_http_3000.membership_excluded: <replaceable>0</replaceable>
cluster.cds_egress_<replaceable>prod</replaceable>_<replaceable>virtual-node-a</replaceable>_http_3000.membership_healthy: <replaceable>3</replaceable>
cluster.cds_egress_<replaceable>prod</replaceable>_<replaceable>virtual-node-a</replaceable>_http_3000.membership_total: <replaceable>3</replaceable>
cluster.cds_egress_<replaceable>prod</replaceable>_<replaceable>virtual-node-a</replaceable>_http_3000.lb_healthy_panic: <replaceable>0</replaceable></programlisting>
        <para>Next, you can look at health checks and membership to understand the number of
            endpoints available and how they are passing healtchecks. In the following example, you
            can see that three endpoints are available (with a single change in membership), and
            that they have all passed health checks. </para>
    <programlisting role="nocopy">cluster.cds_egress_<replaceable>prod</replaceable>_<replaceable>virtual-node-a</replaceable>_http_3000.upstream_cx_connect_fail: <replaceable>0</replaceable>
cluster.cds_egress_<replaceable>prod</replaceable>_<replaceable>virtual-node-a</replaceable>_http_3000.upstream_cx_connect_timeout: <replaceable>0</replaceable>
cluster.cds_egress_<replaceable>prod</replaceable>_<replaceable>virtual-node-a</replaceable>_http_3000.upstream_cx_destroy_local_with_active_rq: <replaceable>48</replaceable>
cluster.cds_egress_<replaceable>prod</replaceable>_<replaceable>virtual-node-a</replaceable>_http_3000.upstream_cx_destroy_remote_with_active_rq: <replaceable>0</replaceable>
cluster.cds_egress_<replaceable>prod</replaceable>_<replaceable>virtual-node-a</replaceable>_http_3000.upstream_cx_destroy_with_active_rq: <replaceable>48</replaceable>
cluster.cds_egress_<replaceable>prod</replaceable>_<replaceable>virtual-node-a</replaceable>_http_3000.upstream_cx_idle_timeout: <replaceable>436</replaceable>
cluster.cds_egress_<replaceable>prod</replaceable>_<replaceable>virtual-node-a</replaceable>_http_3000.upstream_cx_none_healthy: <replaceable>0</replaceable>
cluster.cds_egress_<replaceable>prod</replaceable>_<replaceable>virtual-node-a</replaceable>_http_3000.upstream_cx_overflow: <replaceable>0</replaceable>
cluster.cds_egress_<replaceable>prod</replaceable>_<replaceable>virtual-node-a</replaceable>_http_3000.upstream_cx_pool_overflow: <replaceable>0</replaceable>
cluster.cds_egress_<replaceable>prod</replaceable>_<replaceable>virtual-node-a</replaceable>_http_3000.upstream_cx_protocol_error: <replaceable>0</replaceable></programlisting>
        <para>You can see that the destination in the previous example has never gone into
                <code>panic mode</code>, which means that less than 50% of endpoints are known
            healthy. Had the destination gone into panic mode, you would see a line similar to the
            following:</para>
        <programlisting>cluster.cds_egress_<replaceable>prod</replaceable>_<replaceable>virtual-node-a</replaceable>_http_3000.lb_healthy_panic: <replaceable>559</replaceable></programlisting>
        <para>While panic mode is helpful when there is a systemic issue and you want to route
            requests somewhere, it does mean you are more likely to see failed requests than when
            otherwise healthy.</para>
        <para>Finally, you can look at connection metrics, which tell you how Envoy is managing the
            underlying TCP connections to destinations. One of the more important metrics to monitor
            is the <code>destroy_with_active</code> metrics, because without retries in place, any
            in-flight request is converted into <code>503</code> errors. For guidance in
            troubleshooting common <code>503</code> errors, see <link
                linkend="ts-setup-503-during-deployment"/> and <link
                linkend="ts-connectivity-upstream-connect-failures"/>.</para>
    </section> -->
</chapter>
